/*
 * This file is part of Minotaur.
 * 
 * Minotaur is free software: you can redistribute it and/or modify
 * it under the terms of the GNU Affero General Public License as published
 * by the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 * 
 * Minotaur is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
 * GNU Affero General Public License for more details.
 * 
 * You should have received a copy of the GNU Affero General Public License
 * along with Minotaur. If not, see <https://www.gnu.org/licenses/>.
 */

using System.Text;
using Minotaur.GrammarGeneration.Analysis;
using Minotaur.GrammarGeneration.Models;
using Minotaur.GrammarGeneration.Refinement;
using Minotaur.GrammarGeneration.Validation;

namespace Minotaur.GrammarGeneration;

/// <summary>
/// Main grammar generation orchestrator
/// </summary>
public class GrammarGenerator
{
    private readonly TokenPatternAnalyzer _tokenAnalyzer;
    private readonly SyntaxStructureAnalyzer _syntaxAnalyzer;
    private readonly ParseErrorAnalyzer _errorAnalyzer;
    private readonly GrammarValidator _validator;

    public GrammarGenerator()
    {
        _tokenAnalyzer = new TokenPatternAnalyzer();
        _syntaxAnalyzer = new SyntaxStructureAnalyzer();
        _errorAnalyzer = new ParseErrorAnalyzer();
        _validator = new GrammarValidator();
    }

    /// <summary>
    /// Generate a grammar from source code files
    /// </summary>
    public async Task<Grammar> GenerateGrammarAsync(
        string languageName,
        string[] sourceFiles,
        LanguageContext? context = null,
        IProgress<GrammarGenerationProgress>? progress = null)
    {
        progress?.Report(new GrammarGenerationProgress { Stage = "Initializing", Progress = 0 });

        // 1. Analyze token patterns
        progress?.Report(new GrammarGenerationProgress { Stage = "Analyzing tokens", Progress = 10 });
        var tokenDefinitions = _tokenAnalyzer.AnalyzeSourceCode(sourceFiles);

        // 2. Analyze syntax structure
        progress?.Report(new GrammarGenerationProgress { Stage = "Analyzing syntax", Progress = 30 });
        var productionRules = _syntaxAnalyzer.DiscoverSyntaxPatterns(tokenDefinitions, sourceFiles);

        // 3. Create initial grammar
        progress?.Report(new GrammarGenerationProgress { Stage = "Creating initial grammar", Progress = 50 });
        var grammar = new Grammar
        {
            Name = languageName,
            Language = languageName,
            TokenRules = tokenDefinitions,
            ProductionRules = productionRules,
            Metadata = new Dictionary<string, string>
            {
                ["SourceFiles"] = string.Join(";", sourceFiles),
                ["GeneratedBy"] = "Minotaur Grammar Generator",
                ["GeneratedAt"] = DateTime.UtcNow.ToString("yyyy-MM-dd HH:mm:ss UTC")
            }
        };

        // 4. Apply context-specific enhancements
        if (context != null)
        {
            progress?.Report(new GrammarGenerationProgress { Stage = "Applying context enhancements", Progress = 70 });
            grammar = await ApplyContextEnhancements(grammar, context);
        }

        // 5. Validate and refine
        progress?.Report(new GrammarGenerationProgress { Stage = "Validating grammar", Progress = 90 });
        var validationResult = await _validator.ValidateGrammarAsync(grammar, sourceFiles);
        
        if (validationResult.Errors.Any())
        {
            // Apply refinements based on validation errors
            var errors = validationResult.Errors.Select(ConvertToParseError).ToArray();
            var refinement = _errorAnalyzer.AnalyzeParseErrors(errors, grammar);
            grammar = ApplyRefinement(grammar, refinement);
        }

        progress?.Report(new GrammarGenerationProgress { Stage = "Complete", Progress = 100 });
        return grammar;
    }

    /// <summary>
    /// Generate grammar file content in the standard format
    /// </summary>
    public string GenerateGrammarFile(Grammar grammar)
    {
        var sb = new StringBuilder();

        // Header
        sb.AppendLine($"Grammar: {grammar.Name}");
        sb.AppendLine("TokenSplitter: Space");
        sb.AppendLine("FormatType: EBNF");
        sb.AppendLine();

        // Comment with metadata
        sb.AppendLine("/*");
        sb.AppendLine($" * {grammar.Language} Grammar Definition");
        sb.AppendLine($" * Generated by Minotaur Grammar Generator");
        sb.AppendLine($" * Created: {grammar.Created:yyyy-MM-dd HH:mm:ss UTC}");
        sb.AppendLine($" * Version: {grammar.Version}");
        
        if (grammar.Metadata.Any())
        {
            sb.AppendLine(" *");
            foreach (var (key, value) in grammar.Metadata)
            {
                sb.AppendLine($" * {key}: {value}");
            }
        }
        
        sb.AppendLine(" */");
        sb.AppendLine();

        // Keywords (if any)
        var keywords = grammar.TokenRules.GetPatternsByType(TokenType.Keyword).ToList();
        if (keywords.Any())
        {
            sb.Append("Keywords: ");
            sb.AppendLine(string.Join(", ", keywords.Select(k => k.Name.ToLower())));
            sb.AppendLine();
        }

        // Production rules
        foreach (var rule in grammar.ProductionRules.Rules.OrderByDescending(r => r.Priority))
        {
            sb.AppendLine($"<{rule.Name}> ::= {string.Join(" | ", rule.Alternatives)}");
            
            if (rule.Examples.Any())
            {
                sb.AppendLine($"    // Examples: {string.Join(", ", rule.Examples.Take(2))}");
            }
            
            sb.AppendLine();
        }

        // Token patterns (excluding keywords which are listed separately)
        var nonKeywordTokens = grammar.TokenRules.Patterns
            .Where(p => p.Type != TokenType.Keyword)
            .OrderByDescending(p => p.Priority);

        foreach (var token in nonKeywordTokens)
        {
            if (token.Type == TokenType.Whitespace)
            {
                sb.AppendLine($"<{token.Name}> ::= /{token.Pattern}/ => {{ skip }}");
            }
            else
            {
                sb.AppendLine($"<{token.Name}> ::= /{token.Pattern}/");
            }
            
            if (token.Examples.Any())
            {
                sb.AppendLine($"    // Examples: {string.Join(", ", token.Examples.Take(3))}");
            }
            
            sb.AppendLine();
        }

        return sb.ToString();
    }

    /// <summary>
    /// Save grammar to file
    /// </summary>
    public async Task SaveGrammarAsync(Grammar grammar, string outputPath)
    {
        var grammarContent = GenerateGrammarFile(grammar);
        await File.WriteAllTextAsync(outputPath, grammarContent);
    }

    private async Task<Grammar> ApplyContextEnhancements(Grammar grammar, LanguageContext context)
    {
        // Add context-specific rules based on language features
        if (context.HasNestedScopes)
        {
            AddScopeAwareRules(grammar);
        }

        if (context.HasTypeSystem)
        {
            AddTypeAwareRules(grammar);
        }

        if (context.HasMacroSystem)
        {
            AddMacroExpansionRules(grammar);
        }

        if (context.HasComments && !grammar.TokenRules.Patterns.Any(p => p.Type == TokenType.Comment))
        {
            AddCommentRules(grammar);
        }

        return await Task.FromResult(grammar);
    }

    private void AddScopeAwareRules(Grammar grammar)
    {
        // Add scoping rules
        var scopeRule = new ProductionRule
        {
            Name = "scoped_block",
            Alternatives = new List<string>
            {
                "<LBRACE> <scope_declarations> <RBRACE>"
            },
            Priority = 95,
            Confidence = 0.8
        };

        grammar.ProductionRules.AddRule(scopeRule);
    }

    private void AddTypeAwareRules(Grammar grammar)
    {
        // Add type system rules
        var typeRule = new ProductionRule
        {
            Name = "type_specification",
            Alternatives = new List<string>
            {
                "<primitive_type>",
                "<user_defined_type>",
                "<generic_type>"
            },
            Priority = 85,
            Confidence = 0.8
        };

        grammar.ProductionRules.AddRule(typeRule);
    }

    private void AddMacroExpansionRules(Grammar grammar)
    {
        // Add macro rules
        var macroRule = new ProductionRule
        {
            Name = "macro_definition",
            Alternatives = new List<string>
            {
                "<DEFINE> <identifier> <macro_body>"
            },
            Priority = 80,
            Confidence = 0.7
        };

        grammar.ProductionRules.AddRule(macroRule);
    }

    private void AddCommentRules(Grammar grammar)
    {
        // Add comment tokens
        grammar.TokenRules.AddPattern(new TokenPattern
        {
            Name = "LINE_COMMENT",
            Pattern = @"//[^\r\n]*",
            Type = TokenType.Comment,
            Priority = 120,
            Confidence = 0.9
        });

        grammar.TokenRules.AddPattern(new TokenPattern
        {
            Name = "BLOCK_COMMENT",
            Pattern = @"/\*.*?\*/",
            Type = TokenType.Comment,
            Priority = 120,
            Confidence = 0.9
        });
    }

    private ParseError ConvertToParseError(string error)
    {
        // Convert validation error to ParseError
        return new ParseError
        {
            Type = ParseErrorType.UnexpectedToken,
            Message = error,
            Line = 0,
            Column = 0,
            SourceText = string.Empty
        };
    }

    private Grammar ApplyRefinement(Grammar grammar, GrammarRefinement refinement)
    {
        // Apply the suggested refinement to the grammar
        switch (refinement.Type)
        {
            case RefinementType.AddTokenRule:
                // Parse and add the suggested token rule
                break;
                
            case RefinementType.AddProductionRule:
                // Parse and add the suggested production rule
                break;
                
            case RefinementType.ModifyTokenRule:
                // Modify existing token rule
                break;
                
            case RefinementType.ModifyProductionRule:
                // Modify existing production rule
                break;
        }

        return grammar;
    }
}

/// <summary>
/// Progress information for grammar generation
/// </summary>
public class GrammarGenerationProgress
{
    public string Stage { get; set; } = string.Empty;
    public int Progress { get; set; }
    public string? Details { get; set; }
}