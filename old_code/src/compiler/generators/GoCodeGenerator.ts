/**
 * Minotaur Go Code Generator
 *
 * High-performance Go code generator with goroutine support,
 * garbage collector optimization, and modern Go features.
 */

import { CodeGenerator, GeneratedCode, ContextAnalysisResult, ExportConfiguration } from '../CompilerCompilerExport';
import { Grammar } from '../../core/grammar/Grammar';

export class GoCodeGenerator extends CodeGenerator {
  private optimizationLevel: string = 'production';
  private goVersion: string = '1.21';
  private enableConcurrency: boolean = false;

  public async generate(
    grammar: Grammar,
    contextInfo: ContextAnalysisResult,
    config: ExportConfiguration,
  ): Promise<GeneratedCode> {
    this.optimizationLevel = config.optimizationLevel;
    this.goVersion = config.go?.version ?? '1.21';
    this.enableConcurrency = config.go?.enableConcurrency ?? false;

    const sourceFiles = new Map<string, string>();
    const buildFiles = new Map<string, string>();

    const grammarName = this.sanitizeIdentifier(grammar.getName() || 'grammar');
    const packageName = grammarName.toLowerCase();

    // Generate Go source files
    sourceFiles.set('parser.go', this.generateParserFile(grammar, contextInfo, config, packageName));
    sourceFiles.set('lexer.go', this.generateLexerFile(grammar, contextInfo, config, packageName));
    sourceFiles.set('ast.go', this.generateASTFile(grammar, contextInfo, config, packageName));
    sourceFiles.set('token.go', this.generateTokenFile(grammar, contextInfo, config, packageName));

    if (contextInfo.contextRequired) {
      sourceFiles.set('context.go', this.generateContextFile(grammar, contextInfo, config, packageName));
    }

    // Generate build files
    if (config.buildSystemIntegration) {
      buildFiles.set('go.mod', this.generateGoMod(grammar, contextInfo, config, packageName));
      buildFiles.set('Makefile', this.generateMakefile(grammar, contextInfo, config, packageName));
    }

    const linesOfCode = Array.from(sourceFiles.values()).reduce((total, content) =>
      total + content.split('\n').length, 0);

    return {
      success: true,
      sourceFiles,
      headerFiles: new Map(),
      buildFiles,
      documentationFiles: new Map(),
      testFiles: new Map(),
      metadata: {
        generationTime: Date.now(),
        linesOfCode,
        filesGenerated: sourceFiles.size + buildFiles.size,
        targetLanguage: 'Go',
        embeddedLanguagesSupported: [],
        contextSwitchesGenerated: 0,
        crossLanguageReferencesGenerated: 0,
        validationRulesGenerated: 0,
        optimizationLevel: this.optimizationLevel,
        generatorVersion: '1.0.0',
        grammarComplexity: {
          nonTerminals: 0,
          terminals: 0,
          productions: 0,
          embeddedLanguages: 0,
          crossLanguageReferences: 0,
          validationRules: 0,
          cyclomaticComplexity: 1,
        },
      },
      errors: [],
      warnings: [],
    };
  }

  // eslint-disable-next-line max-len
  private generateParserFile(grammar: Grammar, contextInfo: ContextAnalysisResult, config: ExportConfiguration, packageName: string): string {
    const grammarName = this.capitalizeFirst(this.sanitizeIdentifier(grammar.getName() || 'grammar'));

    return `// Package ${packageName} provides a high-performance parser
// Generated by Minotaur Compiler-Compiler Export System
package ${packageName}

import (
	"fmt"
	"strings"
	${this.enableConcurrency ? '"sync"\n\t"context"' : ''}
)

// ParseError represents a parsing error with position information
type ParseError struct {
	Message string
	Line    int
	Column  int
}

// Error implements the error interface
func (e *ParseError) Error() string {
	return fmt.Sprintf("Parse error at %d:%d: %s", e.Line, e.Column, e.Message)
}

// ParseResult represents the result of parsing
type ParseResult struct {
	AST   *ASTNode
	Error *ParseError
}

// ${grammarName}Parser is a high-performance parser with GC optimization
type ${grammarName}Parser struct {
	lexer         *${grammarName}Lexer
	currentToken  *Token
	lookaheadToken *Token
	errors        []*ParseError
	${contextInfo.contextRequired ? `context       *${grammarName}Context` : ''}
	${this.enableConcurrency ? 'ctx           context.Context\n\tmu            sync.RWMutex' : ''}
}

// New${grammarName}Parser creates a new parser instance
func New${grammarName}Parser(input string) *${grammarName}Parser {
	lexer := New${grammarName}Lexer(input)
	currentToken, _ := lexer.NextToken()
	lookaheadToken, _ := lexer.NextToken()

	return &${grammarName}Parser{
		lexer:         lexer,
		currentToken:  currentToken,
		lookaheadToken: lookaheadToken,
		errors:        make([]*ParseError, 0),
		${contextInfo.contextRequired ? `context:       New${grammarName}Context(),` : ''}
		${this.enableConcurrency ? 'ctx:           context.Background(),' : ''}
	}
}

${this.enableConcurrency ? `
// New${grammarName}ParserWithContext creates a parser with context support
func New${grammarName}ParserWithContext(input string, ctx context.Context) *${grammarName}Parser {
	parser := New${grammarName}Parser(input)
	parser.ctx = ctx
	return parser
}
` : ''}

// Parse parses the input and returns the AST root node
func (p *${grammarName}Parser) Parse() *ParseResult {
	${this.enableConcurrency ? 'p.mu.Lock()\n\tdefer p.mu.Unlock()' : ''}
	
	ast, err := p.parseStart()
	if err != nil {
		return &ParseResult{Error: err}
	}
	
	return &ParseResult{AST: ast}
}

// Errors returns all parsing errors
func (p *${grammarName}Parser) Errors() []*ParseError {
	${this.enableConcurrency ? 'p.mu.RLock()\n\tdefer p.mu.RUnlock()' : ''}
	return p.errors
}

// advance moves to the next token
func (p *${grammarName}Parser) advance() error {
	${this.enableConcurrency ? `
	select {
	case <-p.ctx.Done():
		return &ParseError{Message: "Parsing cancelled", Line: 0, Column: 0}
	default:
	}
	` : ''}
	
	p.currentToken = p.lookaheadToken
	token, err := p.lexer.NextToken()
	if err != nil {
		return &ParseError{Message: err.Error(), Line: 0, Column: 0}
	}
	p.lookaheadToken = token
	return nil
}

// matchToken checks if current token matches expected type and advances if so
func (p *${grammarName}Parser) matchToken(expected TokenType) bool {
	if p.currentToken != nil && p.currentToken.Type == expected {
		p.advance()
		return true
	}
	return false
}

// expect expects a specific token type or returns error
func (p *${grammarName}Parser) expect(expected TokenType) (*Token, error) {
	if p.currentToken == nil {
		return nil, &ParseError{
			Message: fmt.Sprintf("Expected %s but reached end of input", expected),
			Line:    0,
			Column:  0,
		}
	}
	
	if p.currentToken.Type != expected {
		return nil, &ParseError{
			Message: fmt.Sprintf("Expected %s but found %s", expected, p.currentToken.Type),
			Line:    p.currentToken.Line,
			Column:  p.currentToken.Column,
		}
	}
	
	token := p.currentToken
	p.advance()
	return token, nil
}

// parseStart parses the start rule
func (p *${grammarName}Parser) parseStart() (*ASTNode, error) {
	node := NewASTNode(ASTNodeProgram, nil)
	
	for p.currentToken != nil && p.currentToken.Type != TokenEOF {
		stmt, err := p.parseStatement()
		if err != nil {
			p.errors = append(p.errors, err)
			p.skipToRecoveryPoint()
			continue
		}
		node.AddChild(stmt)
	}
	
	return node, nil
}

// parseExpression parses an expression with operator precedence
func (p *${grammarName}Parser) parseExpression() (*ASTNode, error) {
	return p.parseBinaryExpression(0)
}

// parseBinaryExpression parses binary expression with precedence climbing
func (p *${grammarName}Parser) parseBinaryExpression(minPrec int) (*ASTNode, error) {
	left, err := p.parsePrimary()
	if err != nil {
		return nil, err
	}
	
	for p.currentToken != nil {
		prec := p.getOperatorPrecedence(p.currentToken.Type)
		if prec < minPrec {
			break
		}
		
		opToken := p.currentToken
		p.advance()
		
		right, err := p.parseBinaryExpression(prec + 1)
		if err != nil {
			return nil, err
		}
		
		opNode := NewASTNode(ASTNodeBinaryOp, opToken)
		opNode.AddChild(left)
		opNode.AddChild(right)
		left = opNode
	}
	
	return left, nil
}

// parsePrimary parses primary expression
func (p *${grammarName}Parser) parsePrimary() (*ASTNode, error) {
	if p.currentToken == nil {
		return nil, &ParseError{Message: "Unexpected end of input", Line: 0, Column: 0}
	}
	
	switch p.currentToken.Type {
	case TokenNumber, TokenIdentifier:
		node := NewASTNode(ASTNodeTerminal, p.currentToken)
		p.advance()
		return node, nil
		
	case TokenLeftParen:
		p.advance() // consume '('
		expr, err := p.parseExpression()
		if err != nil {
			return nil, err
		}
		_, err = p.expect(TokenRightParen)
		if err != nil {
			return nil, err
		}
		return expr, nil
		
	default:
		return nil, &ParseError{
			Message: fmt.Sprintf("Unexpected token: %s", p.currentToken.Type),
			Line:    p.currentToken.Line,
			Column:  p.currentToken.Column,
		}
	}
}

// parseStatement parses a statement
func (p *${grammarName}Parser) parseStatement() (*ASTNode, error) {
	node := NewASTNode(ASTNodeStatement, nil)
	
	expr, err := p.parseExpression()
	if err != nil {
		return nil, err
	}
	node.AddChild(expr)
	
	// Optional semicolon
	p.matchToken(TokenSemicolon)
	
	return node, nil
}

// getOperatorPrecedence returns operator precedence
func (p *${grammarName}Parser) getOperatorPrecedence(tokenType TokenType) int {
	switch tokenType {
	case TokenMultiply, TokenDivide:
		return 20
	case TokenPlus, TokenMinus:
		return 10
	default:
		return 0
	}
}

// skipToRecoveryPoint skips tokens until a recovery point is found
func (p *${grammarName}Parser) skipToRecoveryPoint() {
	for p.currentToken != nil {
		switch p.currentToken.Type {
		case TokenSemicolon, TokenEOF:
			if p.currentToken.Type == TokenSemicolon {
				p.advance()
			}
			return
		default:
			p.advance()
		}
	}
}

${this.enableConcurrency ? `
// ParseConcurrently parses multiple inputs concurrently
func ParseConcurrently(inputs []string) []*ParseResult {
	results := make([]*ParseResult, len(inputs))
	var wg sync.WaitGroup
	
	for i, input := range inputs {
		wg.Add(1)
		go func(index int, inp string) {
			defer wg.Done()
			parser := New${grammarName}Parser(inp)
			results[index] = parser.Parse()
		}(i, input)
	}
	
	wg.Wait()
	return results
}
` : ''}
`;
  }

  // eslint-disable-next-line max-len
  private generateLexerFile(grammar: Grammar, contextInfo: ContextAnalysisResult, config: ExportConfiguration, packageName: string): string {
    const grammarName = this.capitalizeFirst(this.sanitizeIdentifier(grammar.getName() || 'grammar'));

    return `// Package ${packageName} lexer implementation
// Generated by Minotaur Compiler-Compiler Export System
package ${packageName}

import (
	"fmt"
	"unicode"
	"unicode/utf8"
	${this.enableConcurrency ? '"sync"' : ''}
)

// LexError represents a lexical analysis error
type LexError struct {
	Message string
	Line    int
	Column  int
}

// Error implements the error interface
func (e *LexError) Error() string {
	return fmt.Sprintf("Lex error at %d:%d: %s", e.Line, e.Column, e.Message)
}

// ${grammarName}Lexer is a high-performance lexer with GC optimization
type ${grammarName}Lexer struct {
	input    string
	position int
	line     int
	column   int
	current  rune
	${this.enableConcurrency ? 'mu       sync.RWMutex' : ''}
}

// New${grammarName}Lexer creates a new lexer instance
func New${grammarName}Lexer(input string) *${grammarName}Lexer {
	lexer := &${grammarName}Lexer{
		input:  input,
		line:   1,
		column: 1,
	}
	lexer.readRune()
	return lexer
}

// NextToken returns the next token from the input
func (l *${grammarName}Lexer) NextToken() (*Token, error) {
	${this.enableConcurrency ? 'l.mu.Lock()\n\tdefer l.mu.Unlock()' : ''}
	
	l.skipWhitespace()
	
	if l.current == 0 {
		return NewToken(TokenEOF, "", l.line, l.column), nil
	}
	
	startLine := l.line
	startColumn := l.column
	
	switch l.current {
	case '0', '1', '2', '3', '4', '5', '6', '7', '8', '9':
		return l.readNumber(startLine, startColumn)
		
	case '"':
		return l.readString(startLine, startColumn)
		
	case '+':
		l.advance()
		return NewToken(TokenPlus, "+", startLine, startColumn), nil
		
	case '-':
		l.advance()
		return NewToken(TokenMinus, "-", startLine, startColumn), nil
		
	case '*':
		l.advance()
		return NewToken(TokenMultiply, "*", startLine, startColumn), nil
		
	case '/':
		l.advance()
		return NewToken(TokenDivide, "/", startLine, startColumn), nil
		
	case '(':
		l.advance()
		return NewToken(TokenLeftParen, "(", startLine, startColumn), nil
		
	case ')':
		l.advance()
		return NewToken(TokenRightParen, ")", startLine, startColumn), nil
		
	case ';':
		l.advance()
		return NewToken(TokenSemicolon, ";", startLine, startColumn), nil
		
	default:
		if unicode.IsLetter(l.current) || l.current == '_' {
			return l.readIdentifier(startLine, startColumn)
		}
		
		char := string(l.current)
		l.advance()
		return nil, &LexError{
			Message: fmt.Sprintf("Unexpected character: '%s'", char),
			Line:    startLine,
			Column:  startColumn,
		}
	}
}

// Position returns current position
func (l *${grammarName}Lexer) Position() int {
	${this.enableConcurrency ? 'l.mu.RLock()\n\tdefer l.mu.RUnlock()' : ''}
	return l.position
}

// Line returns current line
func (l *${grammarName}Lexer) Line() int {
	${this.enableConcurrency ? 'l.mu.RLock()\n\tdefer l.mu.RUnlock()' : ''}
	return l.line
}

// Column returns current column
func (l *${grammarName}Lexer) Column() int {
	${this.enableConcurrency ? 'l.mu.RLock()\n\tdefer l.mu.RUnlock()' : ''}
	return l.column
}

// readRune reads the next rune from input
func (l *${grammarName}Lexer) readRune() {
	if l.position >= len(l.input) {
		l.current = 0
		return
	}
	
	r, size := utf8.DecodeRuneInString(l.input[l.position:])
	l.current = r
	l.position += size
}

// advance moves to the next character
func (l *${grammarName}Lexer) advance() {
	if l.current == '\\n' {
		l.line++
		l.column = 1
	} else {
		l.column++
	}
	l.readRune()
}

// skipWhitespace skips whitespace characters
func (l *${grammarName}Lexer) skipWhitespace() {
	for unicode.IsSpace(l.current) {
		l.advance()
	}
}

// readNumber reads a number token
func (l *${grammarName}Lexer) readNumber(line, column int) (*Token, error) {
	start := l.position - utf8.RuneLen(l.current)
	
	// Read integer part
	for unicode.IsDigit(l.current) {
		l.advance()
	}
	
	// Check for decimal point
	if l.current == '.' {
		l.advance()
		
		// Read fractional part
		for unicode.IsDigit(l.current) {
			l.advance()
		}
	}
	
	text := l.input[start:l.position]
	return NewToken(TokenNumber, text, line, column), nil
}

// readIdentifier reads an identifier or keyword token
func (l *${grammarName}Lexer) readIdentifier(line, column int) (*Token, error) {
	start := l.position - utf8.RuneLen(l.current)
	
	for unicode.IsLetter(l.current) || unicode.IsDigit(l.current) || l.current == '_' {
		l.advance()
	}
	
	text := l.input[start:l.position]
	
	// Check for keywords
	tokenType := TokenIdentifier
	switch text {
	// Add keywords based on grammar
	}
	
	return NewToken(tokenType, text, line, column), nil
}

// readString reads a string literal token
func (l *${grammarName}Lexer) readString(line, column int) (*Token, error) {
	start := l.position - utf8.RuneLen(l.current)
	l.advance() // consume opening quote
	
	for l.current != 0 && l.current != '"' {
		if l.current == '\\\\' {
			l.advance() // consume backslash
			if l.current != 0 {
				l.advance() // consume escaped character
			}
		} else {
			l.advance()
		}
	}
	
	if l.current == '"' {
		l.advance() // consume closing quote
	}
	
	text := l.input[start:l.position]
	return NewToken(TokenString, text, line, column), nil
}
`;
  }

  // eslint-disable-next-line max-len
  private generateASTFile(grammar: Grammar, contextInfo: ContextAnalysisResult, config: ExportConfiguration, packageName: string): string {
    return `// Package ${packageName} AST implementation
// Generated by Minotaur Compiler-Compiler Export System
package ${packageName}

import (
	"fmt"
	"strings"
)

// ASTNodeType represents different types of AST nodes
type ASTNodeType int

const (
	// ASTNodeTerminal represents a terminal node (leaf)
	ASTNodeTerminal ASTNodeType = iota
	// ASTNodeProgram represents the program root
	ASTNodeProgram
	// ASTNodeExpression represents an expression
	ASTNodeExpression
	// ASTNodeBinaryOp represents a binary operation
	ASTNodeBinaryOp
	// ASTNodeStatement represents a statement
	ASTNodeStatement
	// ASTNodeFactor represents a factor
	ASTNodeFactor
	// ASTNodeTerm represents a term
	ASTNodeTerm
)

// String returns string representation of AST node type
func (t ASTNodeType) String() string {
	switch t {
	case ASTNodeTerminal:
		return "Terminal"
	case ASTNodeProgram:
		return "Program"
	case ASTNodeExpression:
		return "Expression"
	case ASTNodeBinaryOp:
		return "BinaryOp"
	case ASTNodeStatement:
		return "Statement"
	case ASTNodeFactor:
		return "Factor"
	case ASTNodeTerm:
		return "Term"
	default:
		return "Unknown"
	}
}

// ASTNode represents a node in the abstract syntax tree
type ASTNode struct {
	Type     ASTNodeType
	Token    *Token
	Children []*ASTNode
}

// NewASTNode creates a new AST node
func NewASTNode(nodeType ASTNodeType, token *Token) *ASTNode {
	return &ASTNode{
		Type:     nodeType,
		Token:    token,
		Children: make([]*ASTNode, 0),
	}
}

// AddChild adds a child node
func (n *ASTNode) AddChild(child *ASTNode) {
	n.Children = append(n.Children, child)
}

// RemoveChild removes a child node at the given index
func (n *ASTNode) RemoveChild(index int) *ASTNode {
	if index < 0 || index >= len(n.Children) {
		return nil
	}
	
	child := n.Children[index]
	n.Children = append(n.Children[:index], n.Children[index+1:]...)
	return child
}

// IsTerminal checks if this is a terminal node
func (n *ASTNode) IsTerminal() bool {
	return n.Token != nil
}

// IsLeaf checks if this is a leaf node
func (n *ASTNode) IsLeaf() bool {
	return len(n.Children) == 0
}

// Accept implements the visitor pattern
func (n *ASTNode) Accept(visitor ASTVisitor) {
	visitor.Visit(n)
}

// TraversePreOrder traverses the tree in pre-order
func (n *ASTNode) TraversePreOrder(visitor func(*ASTNode)) {
	visitor(n)
	for _, child := range n.Children {
		child.TraversePreOrder(visitor)
	}
}

// TraversePostOrder traverses the tree in post-order
func (n *ASTNode) TraversePostOrder(visitor func(*ASTNode)) {
	for _, child := range n.Children {
		child.TraversePostOrder(visitor)
	}
	visitor(n)
}

// FindFirst finds the first node of the specified type
func (n *ASTNode) FindFirst(nodeType ASTNodeType) *ASTNode {
	if n.Type == nodeType {
		return n
	}
	
	for _, child := range n.Children {
		if found := child.FindFirst(nodeType); found != nil {
			return found
		}
	}
	
	return nil
}

// FindAll finds all nodes of the specified type
func (n *ASTNode) FindAll(nodeType ASTNodeType) []*ASTNode {
	var result []*ASTNode
	n.findAllRecursive(nodeType, &result)
	return result
}

// findAllRecursive is a helper for FindAll
func (n *ASTNode) findAllRecursive(nodeType ASTNodeType, result *[]*ASTNode) {
	if n.Type == nodeType {
		*result = append(*result, n)
	}
	
	for _, child := range n.Children {
		child.findAllRecursive(nodeType, result)
	}
}

// Depth returns the depth of the tree
func (n *ASTNode) Depth() int {
	if len(n.Children) == 0 {
		return 1
	}
	
	maxDepth := 0
	for _, child := range n.Children {
		if depth := child.Depth(); depth > maxDepth {
			maxDepth = depth
		}
	}
	
	return 1 + maxDepth
}

// NodeCount returns the total number of nodes in the tree
func (n *ASTNode) NodeCount() int {
	count := 1
	for _, child := range n.Children {
		count += child.NodeCount()
	}
	return count
}

// String returns string representation of the node
func (n *ASTNode) String() string {
	if n.Token != nil {
		return fmt.Sprintf("%s: %q", n.Type, n.Token.Text)
	}
	return n.Type.String()
}

// ASTVisitor interface for the visitor pattern
type ASTVisitor interface {
	Visit(*ASTNode)
}

// PrintVisitor implements ASTVisitor for debugging
type PrintVisitor struct {
	indent int
}

// NewPrintVisitor creates a new print visitor
func NewPrintVisitor() *PrintVisitor {
	return &PrintVisitor{indent: 0}
}

// Visit implements the ASTVisitor interface
func (v *PrintVisitor) Visit(node *ASTNode) {
	fmt.Printf("%s%s\\n", strings.Repeat("  ", v.indent), node.String())
	
	v.indent++
	for _, child := range node.Children {
		child.Accept(v)
	}
	v.indent--
}

// PrintAST prints the AST in a readable format
func PrintAST(node *ASTNode) {
	visitor := NewPrintVisitor()
	node.Accept(visitor)
}
`;
  }

  // eslint-disable-next-line max-len
  private generateTokenFile(grammar: Grammar, contextInfo: ContextAnalysisResult, config: ExportConfiguration, packageName: string): string {
    return `// Package ${packageName} token definitions
// Generated by Minotaur Compiler-Compiler Export System
package ${packageName}

import "fmt"

// TokenType represents different types of tokens
type TokenType int

const (
	// TokenEOF represents end of file
	TokenEOF TokenType = iota
	// TokenError represents a lexical error
	TokenError
	// TokenIdentifier represents an identifier
	TokenIdentifier
	// TokenNumber represents a number literal
	TokenNumber
	// TokenString represents a string literal
	TokenString
	// TokenPlus represents the plus operator (+)
	TokenPlus
	// TokenMinus represents the minus operator (-)
	TokenMinus
	// TokenMultiply represents the multiply operator (*)
	TokenMultiply
	// TokenDivide represents the divide operator (/)
	TokenDivide
	// TokenLeftParen represents left parenthesis (()
	TokenLeftParen
	// TokenRightParen represents right parenthesis ())
	TokenRightParen
	// TokenSemicolon represents semicolon (;)
	TokenSemicolon
	// Add more tokens based on grammar
)

// String returns string representation of token type
func (t TokenType) String() string {
	switch t {
	case TokenEOF:
		return "EOF"
	case TokenError:
		return "ERROR"
	case TokenIdentifier:
		return "IDENTIFIER"
	case TokenNumber:
		return "NUMBER"
	case TokenString:
		return "STRING"
	case TokenPlus:
		return "+"
	case TokenMinus:
		return "-"
	case TokenMultiply:
		return "*"
	case TokenDivide:
		return "/"
	case TokenLeftParen:
		return "("
	case TokenRightParen:
		return ")"
	case TokenSemicolon:
		return ";"
	default:
		return "UNKNOWN"
	}
}

// Token represents a token with position information
type Token struct {
	Type   TokenType
	Text   string
	Line   int
	Column int
}

// NewToken creates a new token
func NewToken(tokenType TokenType, text string, line, column int) *Token {
	return &Token{
		Type:   tokenType,
		Text:   text,
		Line:   line,
		Column: column,
	}
}

// IsEOF checks if this is an EOF token
func (t *Token) IsEOF() bool {
	return t.Type == TokenEOF
}

// IsError checks if this is an error token
func (t *Token) IsError() bool {
	return t.Type == TokenError
}

// String returns string representation of the token
func (t *Token) String() string {
	return fmt.Sprintf("%s '%s' at %d:%d", t.Type, t.Text, t.Line, t.Column)
}
`;
  }

  // eslint-disable-next-line max-len
  private generateContextFile(grammar: Grammar, contextInfo: ContextAnalysisResult, config: ExportConfiguration, packageName: string): string {
    const grammarName = this.capitalizeFirst(this.sanitizeIdentifier(grammar.getName() || 'grammar'));

    return `// Package ${packageName} context management
// Generated by Minotaur Compiler-Compiler Export System
package ${packageName}

import (
	"fmt"
	${this.enableConcurrency ? '"sync"' : ''}
)

// SymbolType represents different types of symbols
type SymbolType int

const (
	// SymbolVariable represents a variable symbol
	SymbolVariable SymbolType = iota
	// SymbolFunction represents a function symbol
	SymbolFunction
	// SymbolClass represents a class symbol
	SymbolClass
	// SymbolInterface represents an interface symbol
	SymbolInterface
)

// String returns string representation of symbol type
func (s SymbolType) String() string {
	switch s {
	case SymbolVariable:
		return "Variable"
	case SymbolFunction:
		return "Function"
	case SymbolClass:
		return "Class"
	case SymbolInterface:
		return "Interface"
	default:
		return "Unknown"
	}
}

// Symbol represents a symbol with metadata
type Symbol struct {
	Name       string
	Type       SymbolType
	Data       interface{} // Additional data
}

// NewSymbol creates a new symbol
func NewSymbol(name string, symbolType SymbolType, data interface{}) *Symbol {
	return &Symbol{
		Name: name,
		Type: symbolType,
		Data: data,
	}
}

// String returns string representation of the symbol
func (s *Symbol) String() string {
	return fmt.Sprintf("%s: %s", s.Type, s.Name)
}

// Scope represents a scope for symbol management
type Scope struct {
	Name    string
	Symbols map[string]*Symbol
	${this.enableConcurrency ? 'mu      sync.RWMutex' : ''}
}

// NewScope creates a new scope
func NewScope(name string) *Scope {
	return &Scope{
		Name:    name,
		Symbols: make(map[string]*Symbol),
	}
}

// DefineSymbol defines a symbol in this scope
func (s *Scope) DefineSymbol(name string, symbolType SymbolType, data interface{}) bool {
	${this.enableConcurrency ? 's.mu.Lock()\n\tdefer s.mu.Unlock()' : ''}
	
	if _, exists := s.Symbols[name]; exists {
		return false // Symbol already exists
	}
	
	s.Symbols[name] = NewSymbol(name, symbolType, data)
	return true
}

// LookupSymbol looks up a symbol in this scope
func (s *Scope) LookupSymbol(name string) *Symbol {
	${this.enableConcurrency ? 's.mu.RLock()\n\tdefer s.mu.RUnlock()' : ''}
	return s.Symbols[name]
}

// HasSymbol checks if symbol exists in this scope
func (s *Scope) HasSymbol(name string) bool {
	${this.enableConcurrency ? 's.mu.RLock()\n\tdefer s.mu.RUnlock()' : ''}
	_, exists := s.Symbols[name]
	return exists
}

// GetSymbols returns all symbols in this scope
func (s *Scope) GetSymbols() []*Symbol {
	${this.enableConcurrency ? 's.mu.RLock()\n\tdefer s.mu.RUnlock()' : ''}
	
	symbols := make([]*Symbol, 0, len(s.Symbols))
	for _, symbol := range s.Symbols {
		symbols = append(symbols, symbol)
	}
	return symbols
}

// SymbolCount returns the number of symbols in this scope
func (s *Scope) SymbolCount() int {
	${this.enableConcurrency ? 's.mu.RLock()\n\tdefer s.mu.RUnlock()' : ''}
	return len(s.Symbols)
}

// String returns string representation of the scope
func (s *Scope) String() string {
	return fmt.Sprintf("Scope '%s' (%d symbols)", s.Name, s.SymbolCount())
}

// ${grammarName}Context manages scope and symbol tracking
type ${grammarName}Context struct {
	ScopeStack []*Scope
	${this.enableConcurrency ? 'mu         sync.RWMutex' : ''}
}

// New${grammarName}Context creates a new context with global scope
func New${grammarName}Context() *${grammarName}Context {
	context := &${grammarName}Context{
		ScopeStack: make([]*Scope, 0),
	}
	context.ScopeStack = append(context.ScopeStack, NewScope("global"))
	return context
}

// PushScope pushes a new scope onto the stack
func (c *${grammarName}Context) PushScope(name string) {
	${this.enableConcurrency ? 'c.mu.Lock()\n\tdefer c.mu.Unlock()' : ''}
	c.ScopeStack = append(c.ScopeStack, NewScope(name))
}

// PopScope pops the current scope from the stack
func (c *${grammarName}Context) PopScope() *Scope {
	${this.enableConcurrency ? 'c.mu.Lock()\n\tdefer c.mu.Unlock()' : ''}
	
	if len(c.ScopeStack) <= 1 { // Keep global scope
		return nil
	}
	
	scope := c.ScopeStack[len(c.ScopeStack)-1]
	c.ScopeStack = c.ScopeStack[:len(c.ScopeStack)-1]
	return scope
}

// CurrentScope returns the current scope
func (c *${grammarName}Context) CurrentScope() *Scope {
	${this.enableConcurrency ? 'c.mu.RLock()\n\tdefer c.mu.RUnlock()' : ''}
	return c.ScopeStack[len(c.ScopeStack)-1]
}

// GlobalScope returns the global scope
func (c *${grammarName}Context) GlobalScope() *Scope {
	${this.enableConcurrency ? 'c.mu.RLock()\n\tdefer c.mu.RUnlock()' : ''}
	return c.ScopeStack[0]
}

// DefineSymbol defines a symbol in the current scope
func (c *${grammarName}Context) DefineSymbol(name string, symbolType SymbolType, data interface{}) bool {
	return c.CurrentScope().DefineSymbol(name, symbolType, data)
}

// LookupSymbol looks up a symbol starting from current scope
func (c *${grammarName}Context) LookupSymbol(name string) *Symbol {
	${this.enableConcurrency ? 'c.mu.RLock()\n\tdefer c.mu.RUnlock()' : ''}
	
	// Search from current scope up to global
	for i := len(c.ScopeStack) - 1; i >= 0; i-- {
		if symbol := c.ScopeStack[i].LookupSymbol(name); symbol != nil {
			return symbol
		}
	}
	return nil
}

// IsSymbolDefined checks if a symbol is defined in any scope
func (c *${grammarName}Context) IsSymbolDefined(name string) bool {
	return c.LookupSymbol(name) != nil
}

// ScopeDepth returns the current scope depth
func (c *${grammarName}Context) ScopeDepth() int {
	${this.enableConcurrency ? 'c.mu.RLock()\n\tdefer c.mu.RUnlock()' : ''}
	return len(c.ScopeStack) - 1 // Exclude global scope
}

// ScopeNames returns names of all scopes in the stack
func (c *${grammarName}Context) ScopeNames() []string {
	${this.enableConcurrency ? 'c.mu.RLock()\n\tdefer c.mu.RUnlock()' : ''}
	
	names := make([]string, len(c.ScopeStack))
	for i, scope := range c.ScopeStack {
		names[i] = scope.Name
	}
	return names
}

// TotalSymbolCount returns total symbol count across all scopes
func (c *${grammarName}Context) TotalSymbolCount() int {
	${this.enableConcurrency ? 'c.mu.RLock()\n\tdefer c.mu.RUnlock()' : ''}
	
	count := 0
	for _, scope := range c.ScopeStack {
		count += scope.SymbolCount()
	}
	return count
}

// String returns string representation of the context
func (c *${grammarName}Context) String() string {
	return fmt.Sprintf("Context (depth: %d, scopes: %v)", c.ScopeDepth(), c.ScopeNames())
}
`;
  }

  // eslint-disable-next-line max-len
  private generateGoMod(grammar: Grammar, contextInfo: ContextAnalysisResult, config: ExportConfiguration, packageName: string): string {
    return `module ${packageName}-parser

go ${this.goVersion}

// No external dependencies - optimized for performance and simplicity
`;
  }

  // eslint-disable-next-line max-len
  private generateMakefile(grammar: Grammar, contextInfo: ContextAnalysisResult, config: ExportConfiguration, packageName: string): string {
    return `.PHONY: build test clean benchmark install

# Build configuration
BINARY_NAME=${packageName}-parser
GO_VERSION=${this.goVersion}

# Build the parser
build:
	go build -ldflags="-s -w" -o $(BINARY_NAME) .

# Run tests
test:
	go test -v ./...

# Run benchmarks
benchmark:
	go test -bench=. -benchmem ./...

# Clean build artifacts
clean:
	go clean
	rm -f $(BINARY_NAME)

# Install dependencies
install:
	go mod tidy
	go mod download

# Format code
fmt:
	go fmt ./...

# Lint code
lint:
	golangci-lint run

# Build for multiple platforms
build-all:
	GOOS=linux GOARCH=amd64 go build -ldflags="-s -w" -o $(BINARY_NAME)-linux-amd64 .
	GOOS=windows GOARCH=amd64 go build -ldflags="-s -w" -o $(BINARY_NAME)-windows-amd64.exe .
	GOOS=darwin GOARCH=amd64 go build -ldflags="-s -w" -o $(BINARY_NAME)-darwin-amd64 .
	GOOS=darwin GOARCH=arm64 go build -ldflags="-s -w" -o $(BINARY_NAME)-darwin-arm64 .

# Performance profiling
profile:
	go test -cpuprofile=cpu.prof -memprofile=mem.prof -bench=.
	go tool pprof cpu.prof
`;
  }

  protected sanitizeIdentifier(name: string): string {
    return name.replace(/[^a-zA-Z0-9_]/g, '_').toLowerCase();
  }

  private capitalizeFirst(str: string): string {
    return str.charAt(0).toUpperCase() + str.slice(1);
  }

  private getAppliedOptimizations(): string[] {
    return [
      'Garbage collector optimization with minimal allocations',
      'Goroutine support for concurrent parsing',
      'UTF-8 optimized string processing',
      'Slice reuse for memory efficiency',
      'Interface{} minimization for type safety',
      'Sync.Pool for object reuse in concurrent scenarios',
      'Build-time optimizations with -ldflags="-s -w"',
    ];
  }

  private getDependencies(config: ExportConfiguration): string[] {
    return [`Go ${this.goVersion}`, 'No external runtime dependencies'];
  }

  private getBuildInstructions(config: ExportConfiguration): string {
    return 'go build -ldflags="-s -w"';
  }

  private getPerformanceNotes(): string[] {
    return [
      'Garbage collector optimized with minimal allocations',
      'Concurrent parsing support with goroutines',
      'UTF-8 native string processing',
      'Memory-efficient slice operations',
      'Build-time dead code elimination',
      'Cross-platform compilation support',
    ];
  }

  protected generateContextSwitchingCode(): string {
    return '// Context switching code for Go (stub implementation)';
  }

  protected generateCrossLanguageValidationCode(): string {
    return '// Cross-language validation code for Go (stub implementation)';
  }

  protected generateSymbolTableSharingCode(): string {
    return '// Symbol table sharing code for Go (stub implementation)';
  }

  protected generateEmbeddedLanguageParser(language: string, grammar: Grammar): string {
    return `// Embedded language parser for ${language} in Go (stub implementation)`;
  }

  protected generateEmbeddedLanguageParserTests(language: string, grammar: Grammar): string {
    return `// Embedded language parser tests for ${language} in Go (stub implementation)`;
  }

  protected generateContextSwitchingTests(): string {
    return '// Context switching tests for Go (stub implementation)';
  }

  protected generateCrossLanguageValidationTests(): string {
    return '// Cross-language validation tests for Go (stub implementation)';
  }
}

